#+STARTUP: overview indent
#+TITLE: Dúvidas da E1 do Projeto de Compilador
* E1 2020/2
** DONE 2021-02-04 D0
*** Dúvida #1

Dado esse input:

 #+BEGIN_EXAMPLE
"invalid
true
 #+END_EXAMPLE

 Qual seria o token que deve retornar o erro?

 Por exemplo, nossa primeira solução veria que a primeira linha nao da match
 com uma string (pois string deve terminar com ") e diria que ["] gerou um erro,
 mas retornaria [invalid] como um identificador.

 Modificamos o programa para retornar ["invalid] como o erro, mas isso causa
 alguns problemas, quando a entrada é, por exemplo:

 "string
 in multiple lines"

 Irá retornar ["string] como erro, e a linha seguinte ele irá reconhecer como
 identificadores.

 Minha dúvida é, precisamos nos preocupar com o quê exatamente gera o erro,
 ou apenas que um token de erro seja retornado?

R: Neste caso temos um =TOKEN_ERRO=. Não há necessidade de se preocupar
com o quê exatamente gera o erro, desde que o erro seja gerado no
local correto. No primeiro exemplo aí em cima, o erro é detectado
quando se chega ao final da primeira linha e percebe-se que a string
não foi terminada. Assumimos que strings não podem ter quebra de linha.

*** Dúvida #2

No desenvolvimento e teste da etapa 1 do trabalho de compiladores
tivemos uma dúvida referente a detecção de alguns padrões.  Por
exemplo, se no código aparecesse algo como 

#+BEGIN_EXAMPLE
"1234my_var1"
#+END_EXAMPLE
(sem as aspas duplas) separado por espaços em branco. Nesse caso, o
correto seria considerar
#+BEGIN_EXAMPLE
"1234my_var1"
#+END_EXAMPLE
como um erro léxico, ou considerar como 2 tokens válidos:
#+BEGIN_EXAMPLE
"1234" 
#+END_EXAMPLE
um inteiro e
#+BEGIN_EXAMPLE
"my_var1"
#+END_EXAMPLE
um identificador?  Caso o correto fosse gerar um erro léxico,
acreditamos que seria necessário usar expressões regulares com o
padrão r/s (dependente de contexto) para que considerar apenas os
tokens que possuam algum caractere delimitador.

R: O correto é considerar como um erro léxico. Não vejo uma absoluta
necessidade de usar dependências de contexto mas se o grupo achar
elegante assim o fazer, sintam-se à vontade.

*** Dúvida #3

Oi, professor. O senhor pode disponibilizar um arquivo de texto pra
testar as regex do trabalho? Ajudaria bastante

R: Recomendo ler a especificação e escrever um arquivo de texto com
entradas que respeitam o que consta na especificação. Outro arquivo
texto pode ser criado com entradas que não respeitam a
especificação. Assim podes testar mais amplamente. Fazer isso faz
parte da E1, de maneira implícita (e agora explícita).

*** Dúvida #4 (A, B, C, D)

Lendo com mais cuidado, as especificações da etapa 1 do projeto da
disciplina de Compiladores, acabou me surgindo algumas dúvidas.

A)

Quando se diz que a notação científica é possível e utiliza [...]
seguido um número positivo ou negativo inteiro, isso significa que
devemos impedir que o número 0 seja utilizado, já que não é negativo
nem positivo?

R: Eu não veria necessidade de impedir que o número 0 seja utilizado,
mas considerando o texto da especificação, podemos levar à risca o que
foi escrito e assumir que zero não é positivo nem negativo. Portanto,
sim, zero não pode estar após E e e.

Isso também indica que devemos obrigar a presença do sinal de "+"
antes do número, caso ele seja positivo, ou o sinal é opcional, ou o
sinal é proibido?

R: Eu diria que o sinal é opcional no caso de números positivos,
seguindo inspiração da linguagem C.

B)

Outra dúvida é quanto às expressões-exemplo com aspas duplas no final
da primeira página. Elas seriam do tipo "string"? Não foi
especificado.

R: Sim, são tokens =TK_LIT_STRING=. Veja mais detalhes com uma dúvida
respondida textualmente no fórum.

C)

E quanto a strings/chars, eu devo considerar que elas podem conter
caracteres além dos alfanuméricos (0-9, A-Z, a-z, _) e dos caracteres
especiais (seção 3.2)? Como por exemplo, conter os caracteres \", \n,
\t, \', \0, etc?

R: Não há necessidade de ter e tratar caracteres escapados (antecidos de \).

D)

Uma outra dúvida, é sobre como eu vinculo o meu arquivo scanner.l, ao
arquivo main.c fornecido, essa explicação se encontra em alguma parte
do site que possui as especificações do flex?

R: Veja o video N2 A4 FLEX e obtenha inspiração para construir seu Makefile.

*** Dúvida #5

Sobre a etapa 1 do trabalho, onde o senhor comenta "Lançar erros
lexicos ao encontrar caracteres inválidos na entrada, retornando o
token de erro.", estou em dúvida sobre quão detalhista devo
ser. Comentaste que não era boa prática fazer uma regra genérica (com
.) para capturarmos erros que não foram abordados, porém de que outra
forma podemos garantir que vamos lançar erro quando o usuário digitar
algo inválido?

R: Pois é, tens razão. Mas eu recomendaria só colocar o . para
capturar qualquer coisa _depois_ que todas as ERs para capturar coisas
válidas forem todas colocadas. Assim evita-se dores de cabeça.

Além disso, dentro de strings, devemos permitir caracteres especiais
(como \n e \")? Strings e char podem ser vazios?  Um parêntesis aberto
que não foi fechado constitui um erro léxico?  Quão detalhista
precisamos ser nos erros?

R: Não há necessidade, mas se o grupo quiser implementar, não há
problema. Neste momento é relativamente simples de fazer isso, mas
quando chegarmos na etapa com tabela de símbolos, precisaremos tratar
os caracteres escapados. Isso provavelmente não fará parte da
especificação, mas deixo o grupo à vontade se desejar implementar.

*** Dúvida #6

Não consegui entender o objetivo da funcao =get_line_number=

Explicando o que eu entendi: digamos que tenha digitado o caractere de
ponto e virgula. A função get_line_number deve retornar em qual linha do
scanner.l está o regex que identifica esse ponto e virgula como um
token.

Está correto?

R: Incorreto. Na função =main= do programa temos um laço que a cada
token reconhecido, imprime na saída padrão uma linha informando qual
foi o token, o lexema do token e a linha onde ele foi encontrado (na
entrada do compilador). É neste momento que a função =main= do programa
chama a função =get_line_number=. A função dela é portanto identificar
em qual linha foi reconhecido o último token retornado.

*** Dúvida #7 (A, B e C)

A)

O que deve ser considerado um erro lexico? Na definição diz " Lançaar
erros lexicos ao encontrar caracteres invalidos na entrada". Isso
seria caracteres como €, £, etc, que não fazem parte dos tokens
especiais? Ou algo mais como:

- strings com mais de uma linha?
- comentários multi-linha que não são fechados?
- chars (aspas simples) com mais de um caracter?
- parenteses/chaves/colchete sem par?
- float sem número depois do ponto?
- outros?

R: Sim. Sim. Sim (e também chars sem caractere entre as aspas
simples). Não. Sim. Outros exemplos: 1/ strings sem aspas duplas no
fechamento; 2/ toda e qualquer outra entrada que não atenda ao que
está explicitado na E1.

B)

Também não entendi o que deve mapear para os seguintes tokens: =TK_PR_END=
e =TK_PR_DEFAULT=.

R: São resquícios do passado, por favor ignore-os.

C)

Além disso, tenho dúvidas semelhantes as sque estão no fórum de
discussão, e que ainda não foram respondidas.

R: Respondi textualmente lá no Fórum, dá uma olhada.

*** Outras dúvidas no Fórum!

** DONE 2021-02-07 D1
*** Dúvida #1

O sr. disse que, na aula N2 A4, existe uma explicação quanto a
vinculação do arquivo .l ao arquivo .c (minha dúvida), contudo, eu já
havia visto aquela aula quando realizei a pergunta, e permanci com a
dúvida.

O que lá é explicado não se aplica muito bem, pois lá o sr. escreve
todas as funções dentro do próprio .l (exceto a main, que em um
momento o sr. escreve-a explicitamente, e em outro momento o
sr. importa a main do próprio FLEX), mas não mostra um caso em que se
tenha que vincular o .l a um arquivo externo .c.

E pelo o que o sr. explicou, agora, nesse vídeo de dúvidas, parece que
para vinculá-los, eu tenho que compilar os dois, e depois fazer um
linkagem via makefile (ou gcc?). O sr. poderia me explicar como que eu
faço isso? Desde já agradeço.

R: Vamos fazer uma demonstração.

*** Dúvida #2

Professor, caso eu tenha a linha de código:

char a = 'hello;

O erro retornado deve ser ['hello;], certo?

R: Deve ser identificado o =TOKEN_ERRO=. Como houve a abertura das aspas
espera-se um literal caractere. Ele não acontece, o erro deve estar
localizado na aspa.

*** Dúvida #3

No caso abaixo, com uma entrada que combina aspas simples e um
identificador, está correto o retorno ser assim ou deveria retornar um
token de erro apenas?  A pergunta vale também para entradas do tipo
'xxx" ou "xxx".

Entrada

#+BEGIN_EXAMPLE
'auhsd'
#+END_EXAMPLE

Saída

#+BEGIN_EXAMPLE
1 TOKEN_ERRO [']
1 TK_IDENTIFICADOR auhsd
1 TOKEN_ERRO [']
#+END_EXAMPLE

Caso deva ser retornado apenas um token erro, a solução seria tratar
individualmente todos os possíveis casos de erro?

R: Acredito que basta retornar =1 TOKEN_ERRO [']=. O que vem depois não
importa muito. Não há necessidade de se tratar todos os possíveis
casos de erro, até porque são muitos.

*** Dúvida #4

Professor, uma outra dúvida:

Caso eu tenha no código:

/*
a
b
c

Ou seja, não fechei o comentário de múltiplas linhas, o erro será:
[/*
a
b
c]

certo? Ou devo apenas considerar [/*] como erro?

R: Comentários multilinhas não terminados são um erro léxico.

*** Dúvida #5
**** a)

No código:

int a = 12.;

[12.] deve ser um erro? Ou devo considerar como um inteiro e dois
caracteres especiais ([.] e [;]):

R: A especificação de literais ponto-flutuantes diz que se houver um
ponto, deverá existir dígitos depois. Eu diria que seria um erro.

**** b)

No código:

int a = 5+5;

Devo considerar como dois inteiros, [5] e [+5]?

R: Sim.

**** c)

Uma forma simples de resolver alungs desses problemas seria obrigar
que entre dois tokens tenha um espaço/tab/\n. Isso faria por exemplo
que a string "10um" seja um erro, e não um inteiro seguido de um
identificador. Também faria "2." ser um erro, e não um inteiro mais um
token-ponto. Também impediria o caso do "2.0+2", que poderia ser tanto
um float mal formado, ou um float seguido de um inteiro, ou um float
seguido de um token-mais seguido de um inteiro. O único problema, é
que isso faria que a string "int x = 2;" seja um erro, já que teve um
espaço entre o 2 e ;. Mas então, poderíamos usar essa solução de
obrigar espaços entre tokens?

R: Não recomendo obrigar espaços entre tokens, até porque algo como
2.0+2 (considerando a maioria das ling. de prog.) é algo perfeitamente
válido. Recomendo usar um compilador C (gcc/clang) para fazer testes e
ver o que seria "usualmente aceitável" em casos como esse.

* E1 2020/1
** DONE 2020-08-26

 1) A descrição do padrão de identificadores é a seguinte:

 Os identificadores da linguagem são formados por um caractere
 alfabético seguido de zero ou mais caracteres alfanuméricos, onde
 considera-se caractere alfabético como letras maiúsculas ou minúsculas
 ou o caractere sublinhado e onde dígitos são 0, 1, 2, ..., 9.

 Sendo assim, uma sequência de caracteres sublinhada de qualquer
 tamanho sem nenhuma letra ou dígito é um identificador válido?
 Exemplo: __

 2) Na forma de notação científica do float tem um número positivo ou
    negativo depois do (e|E). Quando o número é positivo é obrigatório
    que ele tenha o sinal +? Ou pode não ter?

 3) O conteúdo de um char pode ser qualquer caracter? Em termos de
    regex, podemos usar o ponto para definir o conteúdo de um char?

 4) O conteúdo de uma string pode ser qualquer caracter? E devemos nos
    preocupar em escapar aspas dentro da string? E com outros
    caracteres especiais, como \n e \t?

 5) Quais caracteres devem ser ignorados? Somente espaço, \n e \t?

 6) Ao testar o input inválido "1nv4l1d0" (que é inválido porque seria
    um identificador começando com número), o nosso trabalho não
    retornou o token de erro, mas sim dois tokens: ~TK_LIT_INT~ [1] e
    ~TK_IDENTIFICADOR~ [nv4l1d0]. Esse comportamento é aceitável? Ou
    devemos incrementar as regras para delimitar limites entre os
    tokens? Se tivermos que delimitar limites entre os tokens, quais
    são os padrões que encerram um token? Caracteres em branco e
    especiais? Ou mais alguma outra coisa?

** DONE 2020-08-28
*** Pergunta #1
 mas um comportamento do analisador no terminal nos deixou com uma dúvida.

 O problema ocorre quando acontece um comentário do tipo composto
 #+BEGIN_EXAMPLE
/* Comentario */
 #+END_EXAMPLE
 No terminal o comportamento é o seguinte:

 #+BEGIN_EXAMPLE
$ ./etapa1
// lucas
float
2 TK_PR_FLOAT [float]
int
3 TK_PR_INT [int]
x = 3 ;
4 TK_IDENTIFICADOR [x]
4 TK_ESPECIAL [=]
4 TK_LIT_INT [3]
4 TK_ESPECIAL [;]
/* Lucas */
float
int
x = 3;
 #+END_EXAMPLE

 Note que após o uso do comentário o programa não responde mais em
 tempo real os tokens, finalizado o programa com Ctrl + D aparece os
 valores:

 #+BEGIN_EXAMPLE
6 TK_PR_FLOAT [float]
7 TK_PR_INT [int]
8 TK_IDENTIFICADOR [x]
8 TK_ESPECIAL [=]
8 TK_LIT_INT [3]
8 TK_ESPECIAL [;]
 #+END_EXAMPLE

 Acontece que quando esse mesma simulação é feita com um arquivo txt
 esse comportamento é ocultado visto que a resposta só é dada no fim do
 arquivo.

 Gostaríamos de saber se esse comportamento é esperado, ou estamos com
 um erro no nosso Trabalho.
*** Pergunta #2

Quais caracteres representam esses tokens?
#define ~TK_OC_FORWARD_PIPE~ 289
#define ~TK_OC_BASH_PIPE~    290

*** Pergunta #3

Tenho uma dúvida que para mim não ficou clara na especificação do E1.
Para identificar tokens literais do tipo string, é permitido que essa
string tenha o par de aspas em linhas diferentes?

Por exemplo:
"essa string
eh valida"

deve ser um token válido?

*** Pergunta #4

Em relação ao retorno de erro. Fica um tanto confuso o que exatamente
tratar como erro. Exemplo que foi abordado no video de dúvidas:

12nome;

É correto retornar o ~TK_LIT_INT[12]~ e ~TOKEN_ERRO [nome]~,
ou teria que se retornar um erro só?

Não seria melhor retornar dois tokens válidos (~TK_LIT_INT[12]~ e
~TK_IDENTIFICADOR[nome]~) que deixar para a análise sintática retornar
um erro de sintaxe?

PS: É preferível que eu mande as minhas dúvidas por email ou no forum
do moodle?

*** Pergunta #5

1. Sobre a parte de notação científica de float, devemos considerar um
   caso como 25E-4 Float ou para a notação precisamos que exista um
   ponto '.' pra descrever ele, como -2.5e-3?

2. Em relação a Strings, devemos tratar strings sem aspas finais ("ex
   string aberta) como um erro total de string ou se podemos apontar
   que as aspas iniciais correspondem ao erro (e que o restante dessa
   string aberta corresponda a outras coisas)?

*** Pergunta #6
sobre a etapa 1 do projeto de compiladores, eu queria saber se é
necessário retornar erro quando se abre aspas, mas não fecha, tipo
"teste ou 't
** DONE 2020-08-30
*** Pergunta #1

Apesar dos diversos testes que estamos fazendo para assegurar o
correto funcionamento do scanner, pensei que seria interessante para
todos se você fornecesse um arquivo de teste e o correspondente output
esperado com alguns "corner cases". Acho que diversas dúvidas de
interpretação da especificação seriam resolvidas assim. Seria
apropriado? Seria possível?

*** Pergunta #2

Estou com algumas dúvidas sobre o trabalho de compiladores:

1) Conforme os vídeos de dúvidas anteriores, as sequências "10." e
   "10.e" não podem ser reconhecidas como float. Assim, elas devem ser
   tratadas como erro, ou o analisador pode reconhecer ~TK_LIT_INT[10]~
   ~TK_ESPECIAL[.]~ e ~TK_LIT_INT[10]~ ~TK_ESPECIAL[.]~ ~TK_IDENTIFICADOR[e]~,
   e tratar esses erros em etapas futuras?

2) Os caracteres especiais que o analisador deve reconhecer são apenas
   os 24 listados na especificação, ou devemos incluir também os
   caracteres que aparecem no switch da função main e não estão na
   seção 3.2?

*** Pergunta #3

   Qual é exatamente o lexema da string e charater? Pelo o que entendi,
   não fariam parte deles seus delimitadores, isto é, " e ', e assim eu
   deveria retornar como match somente a sessão de caracteres entre
   esses delimitadores.

   Além disso, sobre esses literais, tenho dúvidas sobre o critério de
   erro definido no último vídeo. Nele você comenta sobre como, ao
   encontrar uma string aberta, deveríamos retornar o ponto do erro como
   a primeira aspa dupla, o que implicaria que continuaríamos
   reconhecendo as próximas palavras como quaisquer outros possíveis
   tokens. Enquanto, de fato, ambos clang e gcc retornem como ponto do
   erro a primeira aspa dupla, eles não reclamam sobre a falta de
   sentido sobre os próximos tokens, o que me leva a crer que eles
   reconhecem todos os caracteres desde a aspa dupla até o final da
   linha como um token de erro. Não seria uma melhor escolha
   implementarmos o comportamento dessa maneira?

*** Pergunta #4

   Não me ficaram muito claros os detalhes sobre componentes finais da
   nossa entrega. Isto é, entendi que precisamos entregar um diretório
   com um Makefile pronto para construir o executável que será testado,
   mas onde esse executável precisa ser criado (na raiz ou numa pasta
   build ou release ou entrega)? E qual deve ser o nome dele? Precisamos
   fornecer alguma documentação adicional junto a esse diretório, fora a
   documentação do código?

*** Pergunta #5

enquanto fazia o trabalho surgiram algumas dúvidas sobre o uso de +/-
na sinalização de inteiros/floats.

Ao digitar algo do tipo "1+2" (sem espaço algum) existem duas formas
de retornar os tokens:

~TK_LIT_INT[1]~
~TK_LIT_INT[+2]~

ou então
~TK_LIT_INT[1]~
~TK_ESPECIAL[+]~
~TK_LIT_INT[2]~

Qual das maneiras seria a forma correta de separar esta entrada?

*** Pergunta #6

Para o exemplo 123-123 nosso analisador esta identificando
~TK_LIT_INT[123]~ e ~TK_LIT_INT[-123]~. Esse comportamento está correto, ou o
esperado seriam três tokens: ~TK_LIT_INT[123]~ ~TK_ESPECIAL[-]~ ~TK_LIT_INT[123]~?
** DONE 2020-08-31
*** Pergunta #1

Professor, no vídeo respondeste uma pergunta sobre os caracteres
especiais, explicando que haviam na verdade 28 caracteres (e até
mostrou uma definição com 2, mas na definição que temos disponível no
moodle existem de fato apenas 24 caraceteres listados (os caracteres
'?', '~', '@' e '`' não estão presentes). Qual das definições é a
válida ?

*** Comentário sobre a questão do ~TOKEN_ERRO~
